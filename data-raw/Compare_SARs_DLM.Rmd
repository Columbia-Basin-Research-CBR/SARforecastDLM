---
title: "Comparing Model Output"
output: github_document
date: "2025-01-14"
---

Prompt:
d. SAR predictions with no CUI, longest time series possible for each of the three methods
e. Ditto, but using the same start and end years for each of the three time series 
f. Same as d, but with CUI
g. Same as e, but with CUI
Then can talk further at next meeting

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  error = FALSE
)
```

```{r load_libraries, include=FALSE}
library(tidyverse)
library(MARSS)
library(GGally)
library(ggcorrplot)
library(here)
```

```{r, correlation plots, echo=FALSE}
load(here("data/sar_raw_data.rda")) # generated in data-raw/utils_generate_sar_raw_data.R

cor_results <- sar_raw_data %>%
  group_by(index, sar.method) %>%
  summarise(correlation = cor(logit.s, value, use = "complete.obs")) %>%
  ungroup()

cor_matrix <- pivot_wider(cor_results, names_from = index, values_from = correlation) %>%
  column_to_rownames(var = "sar.method") %>%
  as.matrix()

# Plot correlation matrix
ggcorrplot(cor_matrix, 
           # method = "circle",  
           type = "full",       
           lab = TRUE,         
           colors = c("red", "white", "blue"), 
           title = "Correlation Matrix of logit.s and value")


# #pairs
# for (sar in unique(sar_raw_data$sar.method)) {
#   pairs_data <- sar_raw_data %>% 
#     filter(sar.method == !!sar) %>% 
#     pivot_wider(names_from = index, values_from = value) %>% 
#     select(-c(year, sar.method))
#   
#     num_cols <- ncol(pairs_data)
#   
#   # Select the columns dynamically
#   selected_cols <- pairs_data[,c(1:num_cols)]
#   
#  p<- ggpairs(selected_cols, title = paste("Scatterplot Matrix of logit.s and value for", sar))
#   
#  print(p)
# }
```



```{r model_functions_without_cov }
fct_model_single_no_cov<-function(data, index, sar){

  data_train<-data %>% 
  filter(sar.method == !!sar, 
         index == !!index) %>% 
  drop_na() %>% 
    select(-c(index, value))

  years <- data_train$year
  ## number of years of data
  TT <- length(years)
  ## get response variable: logit(survival)
  dat <- matrix(data_train$logit.s, nrow = 1)

  ## number of regr params: slope 
  m <- 1 #changed to intercept only


  ### build DLM

  ## for process eqn
  B <- diag(m)                        ## 2x2; Identity -> changed to 1x1
  U <- matrix(0, nrow = m, ncol = 1)  ## 2x1; both elements = 0 -> changed to 1x1
  Q <- matrix(list(0), m, m)          ## 2x2; all 0 for now -> changed to 1x1
  diag(Q) <- c("q.alpha")   ## 1x1; diag = (q1) #-> changed to only include alpha

  ## for observation eqn
  A <- matrix(0)               ## 1x1; scalar = 0
  R <- matrix("r")             ## 1x1; scalar = r

  ## only need starting values for regr parameters
  inits_list <- list(x0 = matrix(c(0), nrow = m))

  ## list of model matrices & vectors
  mod_list <- list(B = B, U = U, Q = Q, A = A, R = R) 


  ### fit DLM
  # set.seed(1234)
  ## fit univariate DLM
  dlm_train <- MARSS::MARSS(dat, inits = inits_list, model = mod_list)
  # DLM: the matrix of states(x) contains the estimates of the regression parameters (θ). Therefore, we need to look in dlm_1$states for the MLEs of the regression parameters, and in dlm_1$states.se for their standard errors.
  
  return(
    dlm_train = dlm_train
  )
}
```

```{r model_functions_withcov }
fct_model_single<-function(data, index, sar){
  data_train<-data %>% 
  filter(sar.method == !!sar, 
       index == !!index) %>% 
  drop_na()
  
  data_new <- data %>% 
  filter(sar.method == !!sar, 
         index == !!index)
  
    
 years <- data_train$year
  ## number of years of data
  TT <- length(years)
  ## get response variable: logit(survival)
  dat <- matrix(data_train$logit.s, nrow = 1)

  ## get predictor variable
  index <- data_train$value

  ## ## ## z-score the upwelling index
  index_z <- matrix((index - mean(index)) / sqrt(var(index)), nrow = 1)

  index_z_train <- index_z[1:TT]

  ## number of regr params (slope + intercept) = 2
  m <- dim(index_z)[1] + 1

  ### build DLM

  ## for process eqn
  B <- diag(m)                        ## 2x2; Identity
  U <- matrix(0, nrow = m, ncol = 1)  ## 2x1; both elements = 0
  Q <- matrix(list(0), m, m)          ## 2x2; all 0 for now
  diag(Q) <- c("q.alpha", "q.beta")   ## 2x2; diag = (q1,q2) #

  ## for observation eqn
  Z <- array(NA, c(1, m, TT))  ## NxMxT; empty for now
  Z[1,1,] <- rep(1, TT)        ## Nx1; 1's for intercept
  Z[1,2,] <- index_z             ## Nx1; predictor variable
  A <- matrix(0)               ## 1x1; scalar = 0
  R <- matrix("r")             ## 1x1; scalar = r

  ## only need starting values for regr parameters
  inits_list <- list(x0 = matrix(c(0,0), nrow = m))

  ## list of model matrices & vectors
  mod_list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R) 


  ### fit DLM
  # set.seed(1234)
  ## fit univariate DLM
  dlm_train <- MARSS::MARSS(dat, inits = inits_list, model = mod_list)
  # DLM: the matrix of states(x) contains the estimates of the regression parameters (θ). Therefore, we need to look in dlm_1$states for the MLEs of the regression parameters, and in dlm_1$states.se for their standard errors.

  ## forecast
  forecast_df<-MARSS::forecast(dlm_train, h= 1, newdata = list(z = data_new[nrow(data_new),4], y = data_train[nrow(data_train),2]), type = "ytT", interval = "confidence", fun.kf = "MARSSkfss") #forecasting using the last year survival with new covariate data
  print(paste("New data: covariate data ", forecast_df$newdata$z, "with last survival", forecast_df$newdata$y))
  
  return(list(
    dlm_train = dlm_train,
    forecast_df = forecast_df)
  )

}

```

# d. SAR predictions with no CUI, longest time series possible for each of the three methods
```{r run_model_no_cov}
fit_no_cov_sw<-fct_model_single_no_cov(data = sar_raw_data, index = "CUI", sar = "Scheuerell and Williams (2005)") 
fit_no_cov_dart<-fct_model_single_no_cov(data = sar_raw_data, index = "CUI", sar = "DART") #if include 2000 & 2001 results are nonsense
fit_no_cov_cjs<-fct_model_single_no_cov(data = sar_raw_data, index = "CUI", sar = "CJS")
```


```{r run_model_no_cov_plots, echo=FALSE}
#Scheuerell and Williams (2005)
plot(fit_no_cov_sw, plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: Scheuerell and Williams (2005), 1964:2005 with no covariate", line =2)

#DART
plot(fit_no_cov_dart,plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: DART, 2002:2021 with no covariate", line = 2)

#CJS
plot(fit_no_cov_cjs, plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: CJS, 1998:2019 with no covariate ")

```

# e. Ditto, but using the same start and end years for each of the three time series
```{r}
sar_raw_data_00_05<-sar_raw_data %>% 
  filter(year >= 2000 & year <= 2005)

fit_no_cov_sw_00_05<-fct_model_single_no_cov(data = sar_raw_data_00_05, index = "CUI", sar = "Scheuerell and Williams (2005)")
fit_no_cov_dart_00_05<-fct_model_single_no_cov(data = sar_raw_data_00_05, index = "CUI", sar = "DART")
fit_no_cov_cjs_00_05<-fct_model_single_no_cov(data = sar_raw_data_00_05, index = "CUI", sar = "CJS")
```
```{r}
plot(fit_no_cov_sw_00_05, plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: Scheuerell and Williams (2005), 2000:2005 with no covariate", line =2)
plot(fit_no_cov_dart_00_05, plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: DART, 2000:2005 with no covariate", line = 2)
plot(fit_no_cov_cjs_00_05, plot.type = c("fitted.ytT"), silent = TRUE)
title(main = "SAR: CJS, 2000:2005 with no covariate")
```

# f. Same as d (longest time series per SAR), but with CUI

```{r run_model_with_CUI}
fit_sw<-fct_model_single(data = sar_raw_data, index = "CUI", sar = "Scheuerell and Williams (2005)") 
fit_dart<-fct_model_single(data = sar_raw_data %>% filter(between(year, 2002,2021)), index = "CUI", sar = "DART")
fit_cjs<-fct_model_single(data = sar_raw_data, index = "CUI", sar = "CJS")
```


```{r run_model_with_CUI_plots, echo=FALSE}
# "Scheuerell and Williams (2005)"
plot(fit_sw$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_sw$forecast_df)
title(main = "SAR: Scheuerell and Williams (2005), 1964:2005 with CUI", line =2)

# DART
plot(fit_dart$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_dart$forecast_df)
title(main = "SAR: DART, 2002:2020 with CUI", line = 2)

# CJS
plot(fit_cjs$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_cjs$forecast_df)
title(main = "SAR: CJS, 1998:2019 with CUI")
```

# g. Same as e (5 year overlap), but with CUI

```{r}
fit_sw_00_05<-fct_model_single(data = sar_raw_data_00_05, index = "CUI", sar = "Scheuerell and Williams (2005)")
fit_dart_00_05<-fct_model_single(data = sar_raw_data_00_05, index = "CUI", sar = "DART")
fit_cjs_00_05<-fct_model_single(data = sar_raw_data_00_05, index = "CUI", sar = "CJS")
```
```{r}
#Scheuerell and Williams (2005)
plot(fit_sw_00_05$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_sw_00_05$forecast_df)
title(main = "SAR: Scheuerell and Williams (2005), 2000:2005 with CUI", line =2)
#DART
plot(fit_dart_00_05$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_dart_00_05$forecast_df)
title(main = "SAR: DART, 2000:2005 with CUI", line = 2)
#CJS
plot(fit_cjs_00_05$dlm_train, silent = TRUE, plot.type = c("fitted.ytT", "xtT"))
plot(fit_cjs_00_05$forecast_df)
title(main = "SAR: CJS, 2000:2005 with CUI")
```





---- 
Past information to help diagnose (ignore for now)

```{r, eval = FALSE, include=FALSE}
index <- "CUI"
sar <-  "DART" #"Scheurell and Williams (2005)" # "DART"

data<-sar_raw_data %>% 
  filter(sar.method == !!sar, 
         index == !!index) %>% 
  drop_na()

dat.new <- sar_raw_data %>% 
  filter(sar.method == !!sar, 
         index == !!index)

fit_marss<-fct_model_single(data, dat.new)
fit_dart<-fct_model_single(data, dat.new)
fit_cjs<-fct_model_single(data, dat.new)


plot(fit_marss$forecast_df)
plot(fit_dart$forecast_df)
plot(fit_marss$forecast_df)

autoplot(fit_marss$dlm_train)
autoplot(fit_dart$dlm_train)
autoplot(fit_cjs$dlm_train)

#alternatively - by each plot type
#This is the observed data at time t minus the value predicted using the model plus the data up to time  t−1. Innovations residuals should be Gaussian and temporally independent (no autocorrelation).residuals(fit) will return the innovations residuals as a data frame.
kf_out<-MARSS::MARSSkfss(fit_marss$dlm_train)
innov <- kf_out$Innov
innov
#or use basic diagnostics - Chp 6.5 ATSA
resids<-residuals(fit_marss$dlm_train) #.resids = innovs of kf_out (same thing) in data frame format

## Q-Q plot of innovations
qqnorm(resids$.resids, main = "", pch = 16, col = "blue")
## add y=x line for easier interpretation
qqline(resids$.resids)

## Is mean mean of the innovations is significantly different from 0? Use t-test: p-value for t-test of H0: E(innov) = 0; p>>0.05 reject null
t.test(t(innov), mu = 0)$p.value

## plot ACF of innovations
acf(resids$.resids)

#Smoothation residuals 
# Another type of residual used in state-space models is smoothation residuals. This residual at time t is conditioned on all the data. Smoothation residuals are used for outlier detection and can help detect anomalous shocks in the data. Smoothation residuals can be autocorrelated but should fluctuate around 0. The should not have a trend. Looking at your smoothation residuals can help you determine if there are fundamental problems with the structure of your model.
#"tT" for smoothed residuals conditioned on all the data t=1 to 𝑇, aka smoothation residuals.

fit<-fit_dart$dlm_train
resids.tT<-residuals(fit, type = "tT")
#attr(resids.tT, "msg") #error for NAs in resids seem to be a response to DLM structure or how next time step is predicted -- non-issue?

#just data outliers
par(mfrow = c(1, 1))
mresids <- subset(resids, name == "model")
plot(mresids$t, mresids$.std.resids,
  ylab = "model std smoothationl", xlab = "", main = "data outliers"
)
abline(h = 0)
abline(h = c(2,-2), lty=2)


#outliers & sudden level changes 
par(mfrow = c(1, 2))

#sudden level changes x1 & x2
sresids <- subset(resids, name == "state" & .rownames == "X1")
plot(sresids$t, sresids$.std.resids, type="l",
  ylab = "state std smoothation-x1", xlab = "", main = "sudden level changes"
)
abline(h = 0)
abline(h = c(2,-2), lty=2)

sresids <- subset(resids, name == "state" & .rownames == "X2")
plot(sresids$t, sresids$.std.resids, type="l",
  ylab = "state std smoothation -X2", xlab = "", main = "sudden level changes"
)
abline(h = 0)
abline(h = c(2,-2), lty=2)


#Log-likelihood surface - should be smooth and unimodal (if not, could indicates, ridges or flat spots) Chp 6.5
plot(fit$iter.record$logLik, type = "l", main = "Log-Likelihood Over Iterations",
     xlab = "Iteration", ylab = "Log-Likelihood")
# convergence 0= model converged
fit$convergence 

```


```{r, eval=FALSE, include=FALSE}
#select inputs
index <- "CUI"
sar <- "DART"  #"Scheurell and Williams (2005)" # "DART" #"CJS"

data<-sar_raw_data %>% 
  filter(sar.method == !!sar, 
         index == !!index) %>% 
  drop_na()

# fit model
fit_marss_nocov<-fct_model_single_no_cov(data)
fit_cjs_nocov<-fct_model_single_no_cov(data)
fit_dart_nocov<-fct_model_single_no_cov(data)


#plot
autoplot(fit_marss_nocov)
autoplot(fit_cjs_nocov)
autoplot(fit_dart_nocov)


```

Next attempt is using full model (April, September, June) to better explain noise
```{r load_cui_data, eval=FALSE, include=FALSE}
### ERDAPP, NOAA upwelling indice CUI
# Set the URL of the ERDDAP server
url <- "https://upwell.pfeg.noaa.gov/erddap/"

# Get information about the erdCUTI dataset
info <- info(datasetid = "erdUI45mo", url = url)
info # copy max range value from metadata

# Download the dataset
dat <- griddap(info,
               time = c("1964-01-01T00:00:00Z", "2024-11-15T00:00:00Z"), #currently pulling all data to date (adjust as needed)
               latitude = c(45,45)
)

# format time and lat/long
df_cui_raw<-dat$data %>% 
  mutate(time.day = lubridate::ymd_hms(time),
         year = year(time.day),
         month = month(time.day),
         day = day(time.day), 
         adjlong = longitude-360) #set to -180 to 180

## only include april CUI from ERDAPP data (for now)
df_cui<-df_cui_raw %>% 
  filter(month %in% c(4,9,10)) %>% 
  select(year, month, upwelling_index) %>% 
  mutate(month_name = case_when(
      month == 4 ~ "april",
      month == 9 ~ "september",
      month == 10 ~ "october"
    )) %>%
  select(-month) %>%
    pivot_wider(names_from = month_name, values_from = upwelling_index) %>%
    mutate(index = "CUI")


df_ASO<-SalmonSurvCUI %>% 
  inner_join(df_cui, by = "year") %>% 
  select(-CUI.apr)
```


```{r model, eval=FALSE, include=FALSE}
data<-df_ASO

# fct_model_single_ASO<-function(data, data_new){
  
    data<- data %>% 
    select(-index) %>% 
    as.matrix(.)
    
  years <- data[,1]
  ## number of years of data
  TT <- length(years)
  ## get response variable: logit(survival)
  dat <- matrix(data$logit.s, nrow = 1)
  

  # ## get predictor variable
  # index <- data$value
  # 
  # ## ## ## z-score the upwelling index
  # index_z <- matrix((index - mean(index)) / sqrt(var(index)), nrow = 1)
  covariates <- t(data[, c("april", "september", "october")])
  
  the.mean <- apply(covariates, 1, mean, na.rm = TRUE)
  the.sigma <- sqrt(apply(covariates, 1, var, na.rm = TRUE))
  covariates <- (covariates - the.mean) * (1/the.sigma)

  ## number of regr params (slope + intercept) = 2
  m <- dim(covariates)[1] + 1


  ### build DLM

  ## for process eqn
  B <- diag(m)                        ## 2x2; Identity
  U <- matrix(0, nrow = m, ncol = 1)  ## 2x1; both elements = 0
  Q <- "diagonal and unequal" #matrix(list(0), m, m)          ## 2x2; all 0 for now
  # diag(Q) <- c("q.alpha", "q.beta.apr", "q.beta.sept", "q.beta.oct")   ## 2x2; diag = (q1,q2) #

  ## for observation eqn
  Z <- array(NA, c(1, m, TT))  ## NxMxT; empty for now
  Z[1,1,] <- rep(1, TT)        ## Nx1; 1's for intercept
  Z[1,2,] <- covariates[1,]             ## Nx1; predictor variable
   Z[1,3,] <- covariates[2,]             ## Nx1; predictor variable
    Z[1,4,] <- covariates[3,]             ## Nx1; predictor variable
  A <- matrix(0)               ## 1x1; scalar = 0
  R <- matrix("r")             ## 1x1; scalar = r

  ## only need starting values for regr parameters
  inits_list <- list(x0 = matrix(c(0, 0), nrow = m))

  ## list of model matrices & vectors
  mod_list <- list(B = B, U = U, Q = Q, Z = Z, A = A, R = R) 


  ### fit DLM
  # set.seed(1234)
  ## fit univariate DLM
  dlm_train <- MARSS::MARSS(dat, inits = inits_list, model = mod_list)
  # DLM: the matrix of states(x) contains the estimates of the regression parameters (θ). Therefore, we need to look in dlm_1$states for the MLEs of the regression parameters, and in dlm_1$states.se for their standard errors.
# 
#   ## forecast
#   forecast_df<-MARSS::forecast(dlm_train, h= 1, newdata = list(z = data_new[nrow(data_new),4], y = data[nrow(data),2]), type = "ytT", interval = "confidence", fun.kf = "MARSSkfss") #forecasting using the last year survival with new covariate data
#   print(paste("New data: covariate data ", forecast_df$newdata$z, "with last survival", forecast_df$newdata$y))
#   
#   return(list(
#     dlm_train = dlm_train,
#     forecast_df = forecast_df)
#   )
# 
# }
  
  autoplot(dlm_train)
  
R.r <- 0.144924  # From MARSS output
R.r<- 0.15708
var_total <- var(SalmonSurvCUI$logit.s, na.rm = TRUE)  # Calculate from your data

R2 <- 1 - (R.r / var_total)
print(R2)

  autoplot(dlm_train)
  autoplot(fit_marss$dlm_train)
  autoplot(fit_dart$dlm_train)
  
corrplot::corrplot(data$logit.s, data$value)

plot(data$logit.s,data$value)
cor(data$logit.s, data$value)
```


